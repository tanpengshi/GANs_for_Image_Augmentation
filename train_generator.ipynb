{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten,Resizing,GlobalAveragePooling2D,concatenate, Lambda, Conv2DTranspose, Conv2D, BatchNormalization\n",
    "import  tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_resnet = tf.keras.models.load_model('./models/discriminator_resnet')\n",
    "discriminator_model = tf.keras.models.load_model('./models/discriminator')\n",
    "generator = tf.keras.models.load_model('./models/generator')\n",
    "\n",
    "for layer in discriminator_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_glasses_array = np.load('./data/T81-855_glasses_dataset/no_glasses.npy')\n",
    "glasses_array = np.load('./data/T81-855_glasses_dataset/template_glasses.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_array = no_glasses_array\n",
    "\n",
    "target_reconstruction_array = np.array(glasses_array,dtype=np.float32)\n",
    "target_adversarial_array = np.ones(2200).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplingLayer(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim),mean=0,stddev=1)\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def create_generator_model():\n",
    "    input_image = Input(shape=(112, 112,3), name='no_glasses_face')\n",
    "    preprocessed_image = preprocess_input(input_image)\n",
    "    resnet_features = discriminator_resnet(preprocessed_image)\n",
    "    \n",
    "    # Encoder\n",
    "    x1 = GlobalAveragePooling2D()(resnet_features)\n",
    "    x2 = Dense(512,activation=\"relu\")(x1)\n",
    "    x3 = Dense(256,activation=\"relu\")(x2)\n",
    "\n",
    "    # Add Noise at Bottleneck (VAE)\n",
    "    z_mean = Dense(128)(x3)\n",
    "    z_log_var = Dense(128)(x3)\n",
    "    z = SamplingLayer()([z_mean, z_log_var])\n",
    "\n",
    "    # Decoder\n",
    "    d1 = concatenate([z, x3])\n",
    "    d2 = Dense(512, activation=\"relu\")(x3)\n",
    "    d3 = Dense(4096, activation=\"relu\")(d2)\n",
    "\n",
    "    # Reshape to prepare for Deconvolutions\n",
    "    batch_size = tf.shape(d3)[0]\n",
    "    x = tf.reshape(d3, [batch_size, 64, 64, 1])\n",
    "    \n",
    "    # Deconvolutions to get mask\n",
    "    x = Conv2DTranspose(128, (3,3), strides=(1,1), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (17,17), padding='valid', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    mask_image = Conv2D(3, (3,3), padding='same', activation='sigmoid')(x)\n",
    "\n",
    "    # Scale the mask\n",
    "    mask_image = Lambda(lambda x: x * -70.0)(mask_image)\n",
    "\n",
    "    # Add the mask to input image\n",
    "    generated_image = tf.math.add(input_image, mask_image)\n",
    "\n",
    "    return Model(inputs=input_image, outputs=generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape=(112, 112, 3), name='face_image')\n",
    "\n",
    "generator_model = create_generator_model()\n",
    "generated_image = generator_model(input_image)\n",
    "# generated_image = generator(input_image)\n",
    "processed_generated_image = preprocess_input(generated_image)\n",
    "output = discriminator_model(processed_generated_image)\n",
    "\n",
    "model = Model(inputs=input_image,outputs=[output,generated_image,generated_image])\n",
    "\n",
    "def adversarial_loss(y_true, y_pred):\n",
    "    # Adversarial Loss\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)*10\n",
    "\n",
    "def recon_loss_no_glass(y_true, y_pred):    \n",
    "    # Reconstruction Loss using Euclidean (L2) Distance\n",
    "    l2_distance = K.sqrt(K.sum(K.square(y_true - y_pred), axis=[1,2,3]))\n",
    "    recon_loss = K.mean(l2_distance)\n",
    "    # return recon_loss\n",
    "    return recon_loss/200\n",
    "\n",
    "def recon_loss_glass(y_true, y_pred):    \n",
    "    # Reconstruction Loss using Euclidean (L2) Distance\n",
    "    l2_distance = K.sqrt(K.sum(K.square(y_true - y_pred), axis=[1,2,3]))\n",
    "    recon_loss = K.mean(l2_distance)\n",
    "\n",
    "    return recon_loss\n",
    "\n",
    "# Compile the model using the custom loss\n",
    "model.compile(optimizer=RMSprop(learning_rate=2e-5),\n",
    "              loss=[adversarial_loss,recon_loss_no_glass,recon_loss_glass],\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyboardInterruptCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.original_sigint_handler = None\n",
    "        self._training_pid = None\n",
    "        self.best_epoch = None\n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.original_sigint_handler = signal.signal(signal.SIGINT, self.interrupt_training)\n",
    "        self._training_pid = os.getpid()\n",
    "        self.best_val_loss = float('inf')\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        signal.signal(signal.SIGINT, self.original_sigint_handler)\n",
    "        self.original_sigint_handler = None\n",
    "        self._training_pid = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs['val_loss'] < self.best_val_loss:\n",
    "            self.best_epoch = epoch\n",
    "            self.best_val_loss = logs['val_loss']\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        \n",
    "        logs['best_val_loss'] = self.best_val_loss\n",
    "\n",
    "    def interrupt_training(self, signum, frame):\n",
    "        if self._training_pid == os.getpid():\n",
    "            print(f\"Keyboard interrupt detected. Restoring weights from Epoch {self.best_epoch+1}\")\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            self.model.stop_training = True            \n",
    "\n",
    "keyboard_interrupt_callback = KeyboardInterruptCallback()\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    "    monitor='val_loss'\n",
    ")\n",
    "\n",
    "callbacks=[keyboard_interrupt_callback, early_stopping_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x = feature_array,\n",
    "    y = [target_adversarial_array,target_reconstruction_array_no_glass,target_reconstruction_array_glass],\n",
    "    epochs=1000, \n",
    "    batch_size=16,\n",
    "    validation_split=0.05,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generator_model(np.expand_dims(no_glasses_array[0],axis=0))\n",
    "output = np.array(tf.cast(output, tf.uint8))[0]\n",
    "\n",
    "fig = plt.figure(figsize=[2.5,2.5])\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model.save('models/generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_glasses_array = generator_model.predict(no_glasses_array)\n",
    "generated_glasses_array = np.array(tf.cast(generated_glasses_array, tf.uint8))\n",
    "\n",
    "np.save('./data/T81-855_glasses_dataset/generated_glasses_1.npy', generated_glasses_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
